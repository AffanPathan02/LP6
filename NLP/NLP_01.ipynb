{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4db98152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "715b5acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"One Ring to rule them all , One Ring to find them , One Ring to bring them all!! and in the darkness bind them.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a08d85-ae3c-4f87-9393-d9745420eb81",
   "metadata": {},
   "source": [
    "# Whitespace tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89bb426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "549638ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "whitespace_token=WhitespaceTokenizer().tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac873715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'Ring', 'to', 'rule', 'them', 'all', ',', 'One', 'Ring', 'to', 'find', 'them', ',', 'One', 'Ring', 'to', 'bring', 'them', 'all!!', 'and', 'in', 'the', 'darkness', 'bind', 'them.']\n"
     ]
    }
   ],
   "source": [
    "print(whitespace_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae36202-e74a-4bc7-b0ed-896b2927a482",
   "metadata": {},
   "source": [
    "# Treebank Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f44701c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17ff390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "treebank_token=TreebankWordTokenizer().tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6cfa0f0-801f-4599-b342-9fc0df56e476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'Ring', 'to', 'rule', 'them', 'all', ',', 'One', 'Ring', 'to', 'find', 'them', ',', 'One', 'Ring', 'to', 'bring', 'them', 'all', '!', '!', 'and', 'in', 'the', 'darkness', 'bind', 'them', '.']\n"
     ]
    }
   ],
   "source": [
    "print(treebank_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a24549-6231-46d0-b6ad-8cb57bb27658",
   "metadata": {},
   "source": [
    "# Tweet Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a24a87d-ac2d-4e20-a54b-1896e96921c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9e8f3942-92dd-457b-b553-76d854c36fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokenized = TweetTokenizer().tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6c44886-2a12-4273-8bdb-09d67d16959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'Ring', 'to', 'rule', 'them', 'all', ',', 'One', 'Ring', 'to', 'find', 'them', ',', 'One', 'Ring', 'to', 'bring', 'them', 'all', '!', '!', 'and', 'in', 'the', 'darkness', 'bind', 'them', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tweet_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0786e4c7-28a2-4c18-9270-56f159578d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tweet_tokenized == treebank_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5cf3e5-80f6-4684-ba6f-34e44fd2cc94",
   "metadata": {},
   "source": [
    "# MWE Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d37eeef8-ca8a-452f-abb4-45cbf8201e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f5abd4d-3180-4c1d-bd98-76a4e860486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mwe_tokenizer = MWETokenizer([('she'),('take','a','good')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f516ae4-e87c-4152-8ed4-0420be911ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mwe_tokenizer.add_mwe(('Affan'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad144ec5-85d6-4158-9195-d62fd344303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mwe_tokenized = mwe_tokenizer.tokenize(\"affan pathan is a good boy and take regular intervals\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "899f1b65-1b65-44d7-a0dc-c3542d1cb7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'f', 'f', 'a', 'n', ' ', 'p', 'a', 't', 'h', 'a', 'n', ' ', 'i', 's', ' ', 'a', ' ', 'g', 'o', 'o', 'd', ' ', 'b', 'o', 'y', ' ', 'a', 'n', 'd', ' ', 't', 'a', 'k', 'e', ' ', 'r', 'e', 'g', 'u', 'l', 'a', 'r', ' ', 'i', 'n', 't', 'e', 'r', 'v', 'a', 'l', 's']\n"
     ]
    }
   ],
   "source": [
    "print(mwe_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a81d2a1b-66c5-43ef-872d-2afb70d6c8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dypcoe-\n",
      "[nltk_data]     student/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9f4fc6-0237-4218-9888-682f201c9642",
   "metadata": {},
   "source": [
    "# Word Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2c597ca8-8ccf-481f-8040-587f54aaed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_detector=nltk.data.load(\"tokenizers/punkt/english.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7564daf5-8d11-4b17-93f8-49b4108ba6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "efe1aef7-3eb8-483e-b7e3-06505ea12f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'Ring', 'to', 'rule', 'them', 'all', ',', 'One', 'Ring', 'to', 'find', 'them', ',', 'One', 'Ring', 'to', 'bring', 'them', 'all', '!!', 'and', 'in', 'the', 'darkness', 'bind', 'them', '.']\n"
     ]
    }
   ],
   "source": [
    "print(wordpunct_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "02f28a7b-721b-46de-b870-9a817170eb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One Ring to rule them all , One Ring to find them , One Ring to bring them all!!', 'and in the darkness bind them.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_detector.tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6dedf-7749-497e-bffa-584c5eda8360",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7fcfa4b7-1328-48cb-97c0-8b2e42d777f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "72334333-195c-4dfd-b821-708d7342373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "40c8fd97-4182-45f4-8231-21482ad25a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2=\"Going is gone willingly wenting to absurdly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ab78c6a6-466c-481e-bab7-d42cc1234e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ac16cded-12a9-4a29-b80b-ec7869bfb2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going   go\n",
      "is   is\n",
      "gone   gone\n",
      "willingly   willingli\n",
      "wenting   went\n",
      "to   to\n",
      "absurdly   absurdli\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(w,\" \",ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf41c4a-0b71-4854-86c3-98e829dd4e66",
   "metadata": {},
   "source": [
    "# lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0d670b21-0763-461d-855d-ab266db10d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6e018dce-73cb-46ba-b3f3-fa43830e4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3bfffe2e-4496-4e5a-8d80-bed825012f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Going is gone willingly wenting to absurdly\n",
      "Lemmatized Text: go be go willingly wenting to absurdly\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(sentence2)\n",
    "lemmatized_tokens = [token.lemma_ for token in doc]\n",
    "lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "print(\"Original Text:\", sentence2)\n",
    "print(\"Lemmatized Text:\", lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a9a82819-b78a-45c3-8b73-bb6d6dcdfd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/dypcoe-\n",
      "[nltk_data]     student/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "407f71df-4257-4ce1-a531-7e4bd77a6b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Lemmatization\n",
      "Going is gone willingly wenting to absurdly \n",
      "\n",
      "After Lemmatization\n",
      "['Going', 'is', 'gone', 'willingly', 'wenting', 'to', 'absurdly']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stem_words = []\n",
    "for w in words:\n",
    "    x = wordnet_lemmatizer.lemmatize(w)\n",
    "    stem_words.append(x)\n",
    "print('Before Lemmatization')\n",
    "print(sentence2,'\\n')\n",
    "\n",
    "print('After Lemmatization')\n",
    "print(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec9b9f-3e0d-4805-862c-451077539cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
